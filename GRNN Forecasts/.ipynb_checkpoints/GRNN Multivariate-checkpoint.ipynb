{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This loosely code follows the steps outlined by: \n",
    "\n",
    "https://cprosenjit.medium.com/multivariate-time-series-forecasting-using-xgboost-1728762a9eeb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pyGRNN import GRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LassoCV, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Easy format data. Written by me.\n",
    "\"\"\"\n",
    "\n",
    "def format_data(pathname):\n",
    "    df = pd.read_excel(pathname)\n",
    "    df2 = df.drop(columns=['Country Name', 'Country Code'])\n",
    "    df2 = df2.dropna(axis=1, how='all')\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "line 9 in this function used from: \n",
    "https://stackoverflow.com/questions/26921651/how-to-delete-the-last-row-of-data-of-a-pandas-dataframe\n",
    "\"\"\"\n",
    "\n",
    "def fill_na(data):\n",
    "    \n",
    "    df4 = data.fillna(data.mean())\n",
    "    df4.drop(data.tail(1).index,inplace=True) #remove last row\n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by me but utilises function calls to pandas library\n",
    "\"\"\"\n",
    "\n",
    "def x_and_y(data):\n",
    "\n",
    "    X = data.drop(columns='GDP growth (annual %)')\n",
    "    y = data['GDP growth (annual %)']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Selection using Lasso Regression\n",
    "\n",
    "refactored and modifed/added onto from:\n",
    "\n",
    "https://towardsdatascience.com/build-better-regression-models-with-lasso-271ce0f22bd\n",
    "\"\"\"\n",
    "def lassoFeatSelect(X, y, X_train, X_test, y_train, y_test):\n",
    "    featurenames = X.columns.values.tolist()\n",
    "    \n",
    "    lasso_pipe = make_pipeline(preprocessing.StandardScaler(), LassoCV())\n",
    "    lasso_pipe.fit(X_train, y_train)\n",
    "    y_pred = lasso_pipe.predict(X_test)\n",
    "    \n",
    "    lasso_pipe_coef = lasso_pipe[-1].coef_\n",
    "    lasso_selected = list(zip(featurenames, lasso_pipe_coef))\n",
    "    \n",
    "    dflasso = pd.DataFrame(lasso_selected)\n",
    "    dflasso = dflasso.rename(columns={0 : 'Indicator', 1 : 'CoefVal'})\n",
    "    dfLassoFeatures = dflasso[dflasso['CoefVal'] != 0]\n",
    "    lassoFeatureNames = dfLassoFeatures.Indicator.tolist()\n",
    "    \n",
    "    return lassoFeatureNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Selection using Ridge Regression\n",
    "\n",
    "refactored and modified/added onto from: \n",
    "\n",
    "https://towardsdatascience.com/build-better-regression-models-with-lasso-271ce0f22bd\n",
    "\"\"\"\n",
    "\n",
    "def ridgeFeatSelect(X, y, X_train, X_test, y_train, y_test):\n",
    "    featurenames = X.columns.values.tolist()\n",
    "    \n",
    "    ridge_pipe = make_pipeline(preprocessing.StandardScaler(), RidgeCV(alphas=np.arange(0.1,1.0, 0.001)))\n",
    "    ridge_pipe.fit(X_train, y_train)\n",
    "    y_pred = ridge_pipe.predict(X_test)\n",
    "    \n",
    "    ridge_pipe_coef = ridge_pipe[-1].coef_\n",
    "    ridge_selected = list(zip(featurenames, ridge_pipe_coef))\n",
    "\n",
    "    dfRidge = pd.DataFrame(ridge_selected)\n",
    "    dfRidge = dfRidge.rename(columns={0 : 'Indicator', 1 : 'CoefVal'})\n",
    "    dfRidgeFeatures = dfRidge[dfRidge['CoefVal'] != 0]\n",
    "    ridgeFeatureNames = dfRidgeFeatures.Indicator.tolist()\n",
    "\n",
    "    return ridgeFeatureNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b195942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "combination of from: \n",
    "https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663\n",
    "and\n",
    "github documentation: https://github.com/federhub/pyGRNN\n",
    "\n",
    "Two referrenced because similar function used in XGB UV Forecasts, but these lines of code\n",
    "specifically come from the github documentation. Very generic gridsearchCV code.\n",
    "\"\"\"\n",
    "\n",
    "def tune_n(X, y):\n",
    "    hyperparam = {'kernel' : [\"RBF\"],\n",
    "                  'sigma' : list(np.arange(2, 5, 0.001)),\n",
    "                  'calibration' : ['none'],\n",
    "                  'method' : ['Nelder-Mead']\n",
    "                  }\n",
    "    \n",
    "    model = GRNN()\n",
    "    \n",
    "    gscv = GridSearchCV(estimator=model, param_grid=hyperparam,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       verbose=1, cv=10, return_train_score=True)\n",
    "    \n",
    "    gscv.fit(X, y)\n",
    "    \n",
    "    print(\"best hyperparam:\", gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "line 9,10,15 (MDA) adapted and modified from: https://gist.github.com/bshishov/5dc237f59f019b26145648e2124ca1c9\n",
    "\n",
    "line 12 (MAPE) adapted from: https://www.statology.org/mape-python/\n",
    "\"\"\"\n",
    "\n",
    "def performance_metrics(y_test, y_pred):\n",
    "    \n",
    "    sign1 = np.sign(np.array(y_test[1:]) - np.array(y_test[:-1]))\n",
    "    sign2 = np.sign(np.array(y_pred[1:]) - np.array(y_pred[:-1]))\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test )) *100\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    mda = np.mean((sign1 == sign2).astype(int))\n",
    "    mean = np.mean(y_test)\n",
    "    si = (rmse/mean)*100\n",
    "    \n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"MAPE: \", mape)\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"Scatter Index: \", si)\n",
    "    print(\"MDA: \", mda)\n",
    "    print(\"Mean of actual: \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d937244",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = format_data('/Users/farhanhabibie/Desktop/Farhan Thesis Code /UG-Project-Farhan/Multivariate More.xlsx')\n",
    "data2 = data.set_index('Year')\n",
    "filled = fill_na(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by me but utilises function calls to pandas library and sklearn library\n",
    "(for the standardscaler)\n",
    "\n",
    "uncomment X_lasso and X_ridge after running cell 13, when trying to reproduce results.\n",
    "\"\"\"\n",
    "\n",
    "X = filled.drop(columns='GDP growth (annual %)')\n",
    "y = filled['GDP growth (annual %)']\n",
    "\n",
    "X_feat = filled[['Unemployment, female (% of female labor force) (modeled ILO estimate)', 'Foreign direct investment, net outflows (BoP, current US$).1', 'Portfolio investment, net (BoP, current US$).1', 'Foreign direct investment, net inflows (BoP, current US$).1', 'Portfolio equity, net inflows (BoP, current US$).1', 'S&P Global Equity Indices (annual % change)', 'Market capitalization of listed domestic companies (current US$)', 'Market capitalization of listed domestic companies (% of GDP)', 'Listed domestic companies, total', 'Stocks traded, turnover ratio of domestic shares (%)', 'Portfolio investment, bonds (PPG + PNG) (NFL, current US$)', 'Domestic credit to private sector by banks (% of GDP)', 'Bank liquid reserves to bank assets ratio (%)', 'Total reserves in months of imports', 'Claims on other sectors of the domestic economy (annual growth as % of broad money)', 'Net domestic credit (current LCU)', 'Net foreign assets (current LCU)', 'Broad money (current LCU)', 'Interest rate spread (lending rate minus deposit rate, %)', 'Claims on central government, etc. (% GDP)', 'Claims on other sectors of the domestic economy (% of GDP)', 'Domestic credit provided by financial sector (% of GDP)', 'Domestic credit to private sector (% of GDP)', 'Depth of credit information index (0=low to 8=high)', 'Private credit bureau coverage (% of adults)', 'Public credit registry coverage (% of adults)', 'Strength of legal rights index (0=weak to 12=strong)', 'Trade in services (% of GDP)', 'Imports of goods and services (BoP, current US$)', 'Foreign direct investment, net outflows (BoP, current US$)', 'Current account balance (% of GDP)', 'Net errors and omissions (BoP, current US$)', 'Exports of goods and services (BoP, current US$)', 'Goods exports (BoP, current US$)', 'Exports of goods, services and primary income (BoP, current US$)', 'Foreign direct investment, net inflows (BoP, current US$)', 'Portfolio equity, net inflows (BoP, current US$)', 'External debt stocks, total (DOD, current US$)', 'External debt stocks (% of GNI)', 'General government final consumption expenditure (annual % growth)', 'Exports of goods and services (annual % growth)', 'Changes in inventories (current US$)', 'External balance on goods and services (constant LCU)', 'Agriculture, forestry, and fishing, value added (annual % growth)', 'Adjusted savings: education expenditure (current US$)', 'Adjusted savings: carbon dioxide damage (current US$)', 'Adjusted savings: carbon dioxide damage (% of GNI)', 'Adjusted savings: consumption of fixed capital (current US$)', 'Adjusted savings: consumption of fixed capital (% of GNI)', 'Adjusted savings: mineral depletion (current US$)', 'Adjusted net national income (current US$)', 'Adjusted net national income per capita (annual % growth)', 'Discrepancy in expenditure estimate of GDP (constant LCU)', 'GDP, PPP (current international $)', 'GDP per capita growth (annual %)', 'GNI, Atlas method (current US$)', 'GNI growth (annual %)', 'GNI per capita, Atlas method (current US$)', 'GNI per capita growth (annual %)', 'Net primary income (Net income from abroad) (current US$)', 'Taxes less subsidies on products (current US$)', 'Taxes less subsidies on products (current LCU)', 'Net secondary income (Net current transfers from abroad) (current US$)', 'Net secondary income (Net current transfers from abroad) (current LCU)', 'PPP conversion factor, GDP (LCU per international $)']]\n",
    "#X_lasso = filled[lassoFeatSelected]\n",
    "#X_ridge = filled[ridgeFeatSelected]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feat, y, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "\n",
    "#StandardScaler as data follows normal dist\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoFeatSelected = lassoFeatSelect(X, y, X_train, X_test, y_train, y_test)\n",
    "ridgeFeatSelected = ridgeFeatSelect(X, y, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51629149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment and run to perform hyperparam tuning. Commented because takes a long time\n",
    "to keep running this over and over each test.\n",
    "\"\"\"\n",
    "\n",
    "#Hyper param tuning\n",
    "#tune_n(X_train_s, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by me but just uses function calls to the pyGRNN library  \n",
    "\"\"\"\n",
    "\n",
    "model = GRNN(kernel='RBF',calibration='none',sigma=2.46, method='Nelder-Mead')\n",
    "model.fit(X_train_s, y_train)\n",
    "y_pred = model.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code written by me, however (line 9) was also used in a previous Introduction to AI Course I partook in,\n",
    "at City University of London\n",
    "\n",
    "Link to repository provided: \n",
    "https://github.com/LabiKSV/intro-to-ai-farhan-labi/blob/main/Linear%20Regression%20Label%20Encoder.ipynb\n",
    "\"\"\"\n",
    "\n",
    "df_compare = pd.DataFrame({'Actual' : y_test, 'Predicted' : y_pred})\n",
    "df_compare.plot(title='GDP growth Actual vs Predicted')\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Selection\n",
    "\n",
    "from pyGRNN github documentation: https://github.com/federhub/pyGRNN\n",
    "\"\"\"\n",
    "\n",
    "from pyGRNN import feature_selection as FS\n",
    "\n",
    "featurenames = X.columns.values.tolist()\n",
    "\n",
    "#selector = FS.Isotropic_selector(bandwidth = 'rule-of-thumb')\n",
    "#selector.feat_selection(X.to_numpy(), y.ravel(), feature_names=featurenames, strategy='bfs', \n",
    "#                        stop_criterion='first_min')\n",
    "\n",
    "\n",
    "#4 lines copied from documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ad46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Distribution plot from pandas documentation\n",
    "\"\"\"\n",
    "\n",
    "data2.plot.hist(title='Distribution Plot',legend=False, figsize=(50,50))\n",
    "\n",
    "#1 line from documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed095c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Learning Curve to detect overfit/underfit\n",
    "\n",
    "Method from: \n",
    "\n",
    "https://vitalflux.com/learning-curves-explained-python-sklearn-example/amp/\n",
    "and\n",
    "https://www.scikit-yb.org/en/latest/api/model_selection/learning_curve.html#:~:text=Learning%20curves%20can%20be%20generated,see%20in%20the%20following%20examples.\n",
    "\"\"\"\n",
    "\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), model)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipeline, X=X_train,\n",
    "                                                      y=y_train, cv=10,\n",
    "                                                      train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, marker='o', label='Training Accuracy')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.plot(train_sizes, test_mean, marker='x', linestyle='--', label='Validation Accuracy')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Learning Curve for GRNN Before FS After HT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da41590",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fdcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"82 Lines of code\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
