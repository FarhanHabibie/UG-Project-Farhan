{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0355fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_excel('/Users/farhanhabibie/Desktop/Farhan Thesis Code /UG-Project-Farhan/Indonesia Macro Dataset.xlsx')\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that loads and prepares the dataframe. \n",
    "\n",
    "Converts the data into time-series readable.\n",
    "\"\"\"\n",
    "def initialFormat (filepath, indicatorcode):\n",
    "    #Reads the file and creates a dataframe from it\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    #Choose what to forecast using indicator code\n",
    "    df_icode = df.loc[df['Indicator Code'] == indicatorcode]\n",
    "    \n",
    "    #Dropping these columns as they are not needed for the forecast\n",
    "    df_icode = df_icode.drop(columns=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'])\n",
    "    \n",
    "    #Swap axis so it is in the proper format\n",
    "    df_formatted = df_icode.swapaxes(\"index\", \"columns\")\n",
    "    \n",
    "    #Renaming column name to 'values' to make reference easier\n",
    "    for col_names in df_formatted.columns:\n",
    "        name = df_formatted.rename(columns={col_names : \"thing\"})\n",
    "        return name\n",
    "    \n",
    "    return df_formatted\n",
    "\n",
    "#9 Lines Written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d92b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to see how many NA values in the dataset, written by me\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def null_percent(data):\n",
    "    \n",
    "    percentage = (data.isnull().sum()/len(data))*100\n",
    "    \n",
    "    print('Percentage of NA/NAN in this set is: ', percentage)\n",
    "    \n",
    "    #3 Lines Written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e153dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Refactored completely from:\n",
    "https://towardsdatascience.com/time-series-from-scratch-train-test-splits-and-evaluation-metrics-4fd654de1b37\n",
    "\n",
    "Future versions of this function uses this same logic however modifies the function slightly.\n",
    "\"\"\"\n",
    "def train_test_split(data, test_size):\n",
    "    \n",
    "    train = data[:-test_size]\n",
    "    test = data[-test_size:]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "#4 Lines copied from guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8874c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualise the split\n",
    "Also from, but is very generic code:\n",
    "https://towardsdatascience.com/time-series-from-scratch-train-test-splits-and-evaluation-metrics-4fd654de1b37\n",
    "\"\"\"\n",
    "def plot_train_test(train_set, test_set):\n",
    "    ax = plt.plot(train_set, label='Train set')\n",
    "    ax = plt.plot(test_set, label='Test set')\n",
    "    ax = plt.title('GDP Split')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "#4 Lines copied from guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function was refactored from:\n",
    "\n",
    "https://towardsdatascience.com/predicting-electricity-consumption-with-xgbregressor-a11b71104754\n",
    "\n",
    "https://towardsdatascience.com/xgboost-for-time-series-forecasting-dont-use-it-blindly-9ac24dc5dfa9\n",
    "\n",
    "These two guides are written by the same user (Michael Grogan)\n",
    "\"\"\"\n",
    "\n",
    "def create_dataset(df, previous=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range (len(df)-previous-1):\n",
    "        a = df[i:(i+previous), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(df[i+previous, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "#7 Lines Taken directly from guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe810c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "line 11 (MDA) reused from: https://gist.github.com/bshishov/5dc237f59f019b26145648e2124ca1c9\n",
    "\n",
    "line 8 (MAPE) adapted from: https://www.statology.org/mape-python/\n",
    "\n",
    "in future version line 11 (MDA), the code structure has been modified slightly.\n",
    "\"\"\"\n",
    "def performance_metrics(y_test, y_pred):\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test )) *100\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    #r2 = metrics.r2_score(y_test, y_pred)\n",
    "    mda = np.mean((np.sign(y_test[1:] - y_test[:-1]) == np.sign(y_pred[1:] - y_pred[:-1])).astype(int))\n",
    "    mean = np.mean(y_test)\n",
    "    si = (rmse/mean)*100\n",
    "    \n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"MAPE: \", mape)\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"MDA: \", mda)\n",
    "    print(\"Mean of actual: \", mean)\n",
    "    print(\"Scatter Index: \", si)\n",
    "    \n",
    "#13 Lines. 3 From documentation, 1 from github, 9 written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by me but utilised function calls to statsmodels library\n",
    "\"\"\"\n",
    "\n",
    "def plot_ACF(data, lag):\n",
    "    acfData = data.dropna()\n",
    "    print (len(acfData))\n",
    "    plot_acf(acfData, lags=lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = initialFormat('/Users/farhanhabibie/Desktop/Farhan Thesis Code /UG-Project-Farhan/Indonesia Macro Dataset.xlsx', \n",
    "                     'NY.GDP.MKTP.KD.ZG')\n",
    "\n",
    "null_percent(data)\n",
    "data.plot(color='green')\n",
    "#1 Line Written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ACF(data, 28)\n",
    "\n",
    "#1 Line Written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we split, with the train set being 80% and test set being 20%\n",
    "train, test = train_test_split(data, len(data) - int(len(data) * 0.8))\n",
    "train, test = train.dropna(), test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part was refactored from:\n",
    "\n",
    "https://towardsdatascience.com/predicting-electricity-consumption-with-xgbregressor-a11b71104754\n",
    "\n",
    "https://towardsdatascience.com/xgboost-for-time-series-forecasting-dont-use-it-blindly-9ac24dc5dfa9\n",
    "\n",
    "These two guides are written by the same user (Michael Grogan)\n",
    "\"\"\"\n",
    "lookback = 1\n",
    "\n",
    "X_train, Y_train = create_dataset(train.to_numpy(), lookback)\n",
    "X_test, Y_test = create_dataset(test.to_numpy(), lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by me but uses function calls to xgb library\n",
    "\"\"\"\n",
    "\n",
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, max_depth=6, learning_rate=0.3)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a27375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code written by me, however this method (line 9) was also used in a previous Introduction to AI Course I partook in,\n",
    "at City University of London\n",
    "\n",
    "Link to repository provided: \n",
    "https://github.com/LabiKSV/intro-to-ai-farhan-labi/blob/main/Linear%20Regression%20Label%20Encoder.ipynb\n",
    "\"\"\"\n",
    "\n",
    "df_compare = pd.DataFrame({'Actual' : Y_test, 'Predicted' : y_pred})\n",
    "df_compare.plot(title='GDP Actual vs Predicted')\n",
    "performance_metrics(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Starting here is the hyperparameter optimisation for univariate forecasting\n",
    "\n",
    "This piece of code was reused from https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663\n",
    "\n",
    "Fitted for my dataset\n",
    "\"\"\"\n",
    "\n",
    "def tune_n_estimator(X, y):\n",
    "    hyperparam = {'max_depth': [3,6,10],\n",
    "                 'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                 'n_estimators': [5,10,50,100,1000]}\n",
    "    \n",
    "    model = XGBRegressor()\n",
    "    \n",
    "    gscv = GridSearchCV(estimator=model, param_grid=hyperparam,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       verbose=1)\n",
    "    \n",
    "    gscv.fit(X, y)\n",
    "    \n",
    "    print(\"Best hyperparam: \", gscv.best_params_)\n",
    "    \n",
    "#6 Lines from guide, modified by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae5fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Commented out because not needed. Uncomment at need.\n",
    "\"\"\"\n",
    "\n",
    "#tune_n_estimator(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"71 Lines of code, 10 import statements\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
