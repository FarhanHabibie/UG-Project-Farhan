{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import statistics\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb464049",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that loads and prepares the dataframe. \n",
    "\n",
    "Converts the data into time-series readable.\n",
    "\"\"\"\n",
    "def initialFormat (filepath, indicatorcode):\n",
    "    #Reads the file and creates a dataframe from it\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    #Choose what to forecast using indicator code\n",
    "    df_icode = df.loc[df['Indicator Code'] == indicatorcode]\n",
    "    \n",
    "    #Dropping these columns as they are not needed for the forecast\n",
    "    df_icode = df_icode.drop(columns=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'])\n",
    "    \n",
    "    #Swap axis so it is in the proper format\n",
    "    df_formatted = df_icode.swapaxes(\"index\", \"columns\")\n",
    "    \n",
    "    #Renaming column name to 'values' to make reference easier\n",
    "    for col_names in df_formatted.columns:\n",
    "        name = df_formatted.rename(columns={col_names : \"Val\"})\n",
    "        return name\n",
    "    \n",
    "    return df_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Refactored from: \n",
    "\n",
    "https://cprosenjit.medium.com/10-time-series-forecasting-methods-we-should-know-291037d2e285\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def shift_dataframe(data):\n",
    "    \n",
    "    data[\"Target\"] = data.Val.shift(-1)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767acd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "adapted and modified from: \n",
    "https://towardsdatascience.com/time-series-from-scratch-train-test-splits-and-evaluation-metrics-4fd654de1b37\n",
    "\"\"\"\n",
    "\n",
    "def train_test_split(data):\n",
    "    \n",
    "    train = data[:int(len(data)*0.8)]\n",
    "    test = data[int(len(data) * 0.8):]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "line 8 in this function reused from: \n",
    "https://stackoverflow.com/questions/26921651/how-to-delete-the-last-row-of-data-of-a-pandas-dataframe\n",
    "\"\"\"\n",
    "\n",
    "def mean_imputation(data):\n",
    "    filled = data.fillna(data.mean())\n",
    "    filled.drop(data.tail(1).index,inplace=True) #remove last row\n",
    "    \n",
    "    return filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is refactored from machine learning mastery to fit my data:\n",
    "\n",
    "https://machinelearningmastery.com/xgboost-for-time-series-forecasting/\n",
    "\"\"\"\n",
    "def xgboost_model(train, X_test):\n",
    "    train = np.asarray(train)\n",
    "    #Split into X_train and y_train\n",
    "    X_train, y_train = train[:,0:1], train[:, -1]\n",
    "    \n",
    "    model = XGBRegressor(objective='reg:squarederror', n_estimators=5, max_depth=3, learning_rate=0.3)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    y_pred = model.predict(np.asarray([X_test]))\n",
    "    \n",
    "    return y_train, X_train, y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b20f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is refactored from machine learning mastery:\n",
    "\n",
    "https://machinelearningmastery.com/xgboost-for-time-series-forecasting/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def walk_forward_validation(data):\n",
    "    predictions = list()\n",
    "    \n",
    "    train, test = train_test_split(data)\n",
    "    \n",
    "    history = [x for x in train]\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        \n",
    "        X_test, y_test = test[i, :-1], test[i, -1]\n",
    "        \n",
    "        y_train, X_train ,y_pred = xgboost_model(history, X_test)\n",
    "        \n",
    "        predictions.append(y_pred)\n",
    "        \n",
    "    return y_train, X_train, test[:, -1], predictions\n",
    "\n",
    "#9 Lines taken exactly from guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This piece of code was reused and slightly modified from: \n",
    "https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663\n",
    "\n",
    "Fitted for my model\n",
    "\"\"\"\n",
    "\n",
    "def tune_n_estimator(X, y):\n",
    "    hyperparam = {'max_depth': [3,6,10],\n",
    "                 'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                 'n_estimators': [5,10,50,100,1000]}\n",
    "    \n",
    "    model = XGBRegressor()\n",
    "    \n",
    "    gscv = GridSearchCV(estimator=model, param_grid=hyperparam,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       verbose=1)\n",
    "    \n",
    "    gscv.fit(X, y)\n",
    "    \n",
    "    print(\"Best hyperparam: \", gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96726895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "line 7,8,13 (MDA) adapted and modified from: https://gist.github.com/bshishov/5dc237f59f019b26145648e2124ca1c9\n",
    "\n",
    "line 12 (MAPE) adapted from: https://www.statology.org/mape-python/\n",
    "\"\"\"\n",
    "\n",
    "def performance_metrics(y_test, y_pred):\n",
    "    \n",
    "    sign1 = np.sign(np.array(y_test[1:]) - np.array(y_test[:-1]))\n",
    "    sign2 = np.sign(np.array(y_pred[1:]) - np.array(y_pred[:-1]))\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test )) *100\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    mda = np.mean((sign1 == sign2).astype(int))\n",
    "    mean = np.mean(y_test)\n",
    "    si = (rmse/mean)*100\n",
    "    \n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"MAPE: \", mape)\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"Scatter Index: \", si)\n",
    "    print(\"MDA: \", mda)\n",
    "    print(\"Mean of actual: \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Commented out line was the line I used for local testing. Uncommented 'data ='\n",
    "should be good for universal path\n",
    "\n",
    "universal path with help from: \n",
    "\n",
    "https://stackoverflow.com/questions/50119792/python-import-excel-file-using-relative-path\n",
    "\n",
    "INDICATOR CODES:\n",
    "\n",
    "GDP GROWTH = NY.GDP.MKTP.KD.ZG\n",
    "\n",
    "INFLATION = NY.GDP.DEFL.KD.ZG\n",
    "\n",
    "UNEMPLOYEMENT MALE = SL.UEM.TOTL.MA.ZS\n",
    "\n",
    "UNEMPLOYMENT FEMALE = SL.UEM.TOTL.FE.ZS\n",
    "\n",
    "REAL INTEREST RATE = FR.INR.RINR\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#data = initialFormat('/Users/farhanhabibie/Desktop/Farhan Thesis Code /UG-Project-Farhan/Indonesia Macro Dataset.xlsx', \n",
    "#                    'NY.GDP.MKTP.KD.ZG')\n",
    "\n",
    "data = initialFormat(r'./../Indonesia Macro Dataset.xlsx', 'NY.GDP.MKTP.KD.ZG')\n",
    "\n",
    "filled = mean_imputation(data)\n",
    "shifted = shift_dataframe(filled)\n",
    "finalData = shifted.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e21844",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train, X_train, actual, predicted = walk_forward_validation(finalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using X_train and Y_train due to how the target variable works for\n",
    "time series forecast with XGBoost\n",
    "\"\"\"\n",
    "#tune_n_estimator(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da1d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = data.fillna(data.mean())\n",
    "dtest.drop(data.tail(1).index, inplace=True)\n",
    "newindextest = dtest[int(len(data)*0.8):]\n",
    "newindex = newindextest.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f936d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code written by me, however (line 9) was also used in a previous Introduction to AI Course I partook in,\n",
    "at City University of London\n",
    "\n",
    "Link to repository provided: \n",
    "https://github.com/LabiKSV/intro-to-ai-farhan-labi/blob/main/Linear%20Regression%20Label%20Encoder.ipynb\n",
    "\"\"\"\n",
    "\n",
    "df_compare = pd.DataFrame({'Actual' : actual, 'Predicted' : predicted})\n",
    "df_compare.index = newindex\n",
    "df_compare.plot(title='Unemployment (M) Actual vs Predicted')\n",
    "performance_metrics(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calc variance\n",
    "\n",
    "used this guide for formula: https://www.scribbr.com/statistics/variance/\n",
    "\"\"\"\n",
    "\n",
    "dataMean = data.dropna().mean()\n",
    "#print(dataMean)\n",
    "n_minus_one = len(X_train) - 1\n",
    "summed = 0\n",
    "for vals in X_train:\n",
    "        subtracted = vals - dataMean\n",
    "        squared = subtracted ** 2\n",
    "        summed = summed + squared\n",
    "\n",
    "#print(summed)\n",
    "\n",
    "varianced = summed / n_minus_one\n",
    "print(\"Variance = \", varianced)\n",
    "\n",
    "#9 lines written by me after reading formula from guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)\n",
    "plt.title('Real Interest Rate Actual Data')\n",
    "\n",
    "#2 lines written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Learning Curve to detect overfit/underfit\n",
    "\n",
    "Method from: \n",
    "\n",
    "https://vitalflux.com/learning-curves-explained-python-sklearn-example/amp/\n",
    "and\n",
    "https://www.scikit-yb.org/en/latest/api/model_selection/learning_curve.html#:~:text=Learning%20curves%20can%20be%20generated,see%20in%20the%20following%20examples.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pipeline = make_pipeline(XGBRegressor(objective='reg:squarederror', n_estimators=1000, \n",
    "                                                        max_depth=6, learning_rate = 0.3))\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipeline, X=X_train,\n",
    "                                                      y=y_train, cv=5,\n",
    "                                                      train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, marker='o', label='Training Accuracy')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.plot(train_sizes, test_mean, marker='x', linestyle='--', label='Validation Accuracy')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Learning Curve, XGB Univariate Real Interest Rate')\n",
    "\n",
    "#14 lines taken directly from guide, integrated with my model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "101 Total Lines of code\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
