{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac786c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General methodology and structure of code was from me however, it was easy to come up with\n",
    "the structure as I had learnt from previous xgb versions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyGRNN import GRNN\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#8 lines import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c351b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#3 lines written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that loads and prepares the dataframe. \n",
    "\n",
    "Converts the data into time-series readable.\n",
    "\"\"\"\n",
    "def initialFormat (filepath, indicatorcode):\n",
    "    #Reads the file and creates a dataframe from it\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    #Choose what to forecast using indicator code\n",
    "    df_icode = df.loc[df['Indicator Code'] == indicatorcode]\n",
    "    \n",
    "    #Dropping these columns as they are not needed for the forecast\n",
    "    df_icode = df_icode.drop(columns=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'])\n",
    "    \n",
    "    #Swap axis so it is in the proper format\n",
    "    df_formatted = df_icode.swapaxes(\"index\", \"columns\")\n",
    "    \n",
    "    #Renaming column name to 'values' to make reference easier\n",
    "    for col_names in df_formatted.columns:\n",
    "        name = df_formatted.rename(columns={col_names : \"Val\"})\n",
    "        return name\n",
    "    \n",
    "    return df_formatted\n",
    "\n",
    "#9 Lines written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54943fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Refactored from: \n",
    "\n",
    "https://cprosenjit.medium.com/10-time-series-forecasting-methods-we-should-know-291037d2e285\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def shift_dataframe(data):\n",
    "    #The value in \"shift(-x)\" is the lookback period in this case 1.\n",
    "    data[\"Target\"] = data.Val.shift(-1)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#4 lines copied from guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96920876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "adapted and modified from:\n",
    "https://towardsdatascience.com/time-series-from-scratch-train-test-splits-and-evaluation-metrics-4fd654de1b37\n",
    "\"\"\"\n",
    "\n",
    "def train_test_split(data):\n",
    "    \n",
    "    train = data[:int(len(data)*0.8)]\n",
    "    test = data[int(len(data)*0.8):]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "line 8 in this function used from: \n",
    "https://stackoverflow.com/questions/26921651/how-to-delete-the-last-row-of-data-of-a-pandas-dataframe\n",
    "\"\"\"\n",
    "\n",
    "def mean_imputation(data):\n",
    "    filled = data.fillna(data.mean())\n",
    "    filled.drop(data.tail(1).index,inplace=True) #remove last row\n",
    "    \n",
    "    return filled\n",
    "\n",
    "#3 lines written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "line 9,10,15 (MDA) adapted and modified from: https://gist.github.com/bshishov/5dc237f59f019b26145648e2124ca1c9\n",
    "\n",
    "line 12 (MAPE) adapted from: https://www.statology.org/mape-python/\n",
    "\"\"\"\n",
    "\n",
    "def performance_metrics(y_test, y_pred):\n",
    "    \n",
    "    sign1 = np.sign(np.array(y_test[1:]) - np.array(y_test[:-1]))\n",
    "    sign2 = np.sign(np.array(y_pred[1:]) - np.array(y_pred[:-1]))\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test )) *100\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    mda = np.mean((sign1 == sign2).astype(int))\n",
    "    mean = np.mean(y_test)\n",
    "    si = (rmse/mean)*100\n",
    "    \n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"MAPE: \", mape)\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"Scatter Index: \", si)\n",
    "    print(\"MDA: \", mda)\n",
    "    print(\"Mean of actual: \", mean)\n",
    "    \n",
    "#13 Lines. 3 From documentation, 1 from github, 9 written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f436abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = initialFormat('/Users/farhanhabibie/Desktop/Farhan Thesis Code /UG-Project-Farhan/Indonesia Macro Dataset.xlsx', \n",
    "                     'FR.INR.RINR')\n",
    "\n",
    "filled = mean_imputation(data)\n",
    "shifted = shift_dataframe(filled)\n",
    "\n",
    "#Train test and split used for actual training\n",
    "train, test = train_test_split(shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24514d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Written by me\"\n",
    "\n",
    "X_train = train.Val.values.reshape(-1,1)\n",
    "y_train = train.Target.values\n",
    "X_test = test.Val.values.reshape(-1,1)\n",
    "y_test = test.Target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "copied from https://github.com/federhub/pyGRNN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "IGRNN = GRNN()\n",
    "params_IGRNN = {'kernel':[\"RBF\"],\n",
    "                'sigma' : list(np.arange(0.1, 4, 0.01)),\n",
    "                #'n_splits' : list(np.arange(2,len(X_train),1)),\n",
    "                'calibration' : ['none'],\n",
    "                'method' : ['Nelder-Mead']\n",
    "                 }\n",
    "grid_IGRNN = GridSearchCV(estimator=IGRNN,\n",
    "                          param_grid=params_IGRNN,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          cv=5,\n",
    "                          verbose=1\n",
    "                          )\n",
    "grid_IGRNN.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparam: \", grid_IGRNN.best_params_)\n",
    "\n",
    "best_model = grid_IGRNN.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "#7 lines compied from documentation on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by me but just uses function calls to pyGRNN library\n",
    "\n",
    "two models created, one after hyperparam tuning and this one (line 7,8,9) before hyperparam tuning\n",
    "\n",
    "Uncomment to test for models before hyperparameter tuning\n",
    "\"\"\"\n",
    "\n",
    "#model = GRNN(kernel='RBF', calibration='warm_start', seed=42, method='Nelder-Mead',n_splits=10)\n",
    "#model.fit(X_train, y_train)\n",
    "#y_pred_b4ht = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = data.fillna(data.mean())\n",
    "dtest.drop(data.tail(1).index, inplace=True)\n",
    "newindextest = dtest[int(len(data)*0.8):]\n",
    "newindex = newindextest.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b503902",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code written by me, however (line 9) was also used in a previous Introduction to AI Course I partook in,\n",
    "at City University of London\n",
    "\n",
    "Link to repository provided: \n",
    "https://github.com/LabiKSV/intro-to-ai-farhan-labi/blob/main/Linear%20Regression%20Label%20Encoder.ipynb\n",
    "\"\"\"\n",
    "\n",
    "df_compare = pd.DataFrame({'Actual' : y_test, 'Predicted' : y_pred})\n",
    "df_compare.index = newindex\n",
    "df_compare.plot(title='Real Interest Rate Actual vs Predicted')\n",
    "performance_metrics(y_test, y_pred)\n",
    "\n",
    "#5 lines written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Learning Curve to detect overfit/underfit\n",
    "\n",
    "Method and code adapted from: \n",
    "\n",
    "https://vitalflux.com/learning-curves-explained-python-sklearn-example/amp/\n",
    "and\n",
    "https://www.scikit-yb.org/en/latest/api/model_selection/learning_curve.html#:~:text=Learning%20curves%20can%20be%20generated,see%20in%20the%20following%20examples.\n",
    "\"\"\"\n",
    "\n",
    "pipeline = make_pipeline(best_model)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipeline, X=X_train,\n",
    "                                                      y=y_train, cv=5,\n",
    "                                                      train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, marker='o', label='Training Accuracy')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.plot(train_sizes, test_mean, marker='x', linestyle='--', label='Validation Accuracy')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Learning Curve, GRNN Unemployment (F)')\n",
    "\n",
    "#14 lines taken directly from guide, integrated with my model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20015f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "81 Lines of code\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
